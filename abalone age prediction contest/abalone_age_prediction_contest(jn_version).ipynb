{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5534ab",
   "metadata": {
    "id": "bd5534ab"
   },
   "source": [
    "## 전복 나이 예측 경진대회\n",
    "전복 데이터를 기반으로 전복의 나이를 예측해주세요!\n",
    "\n",
    "### 1. train.csv : 학습 데이터\n",
    "- id : 샘플 아이디\n",
    "- Gender : 전복 성별\n",
    "- Lenght : 전복 길이\n",
    "- Diameter : 전복 둘레\n",
    "- Height : 전복 키 \n",
    "- Whole : Weight : 전복 전체 무게\n",
    "- Shucked Weight : 껍질을 제외한 무게\n",
    "- Viscra Weight : 내장 무게\n",
    "- Shell Weight : 껍질 무게\n",
    "- Target : 전복 나이\n",
    "\n",
    "\n",
    "### 2. test.csv : 테스트 데이터\n",
    "- id : 샘플 아이디\n",
    "- Gender : 전복 성별\n",
    "- Lenght : 전복 길이\n",
    "- Diameter : 전복 둘레\n",
    "- Height : 전복 키 \n",
    "- Whole : Weight : 전복 전체 무게\n",
    "- Shucked Weight : 껍질을 제외한 무게\n",
    "- Viscra Weight : 내장 무게\n",
    "- Shell Weight : 껍질 무게\n",
    "\n",
    "\n",
    "### 3. sample_submissoin.csv : 제출 양식\n",
    "- id : 샘플 아이디\n",
    "- Target : 전복 나이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c0191",
   "metadata": {
    "id": "937c0191"
   },
   "source": [
    "### `1.` 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51717c30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21297,
     "status": "ok",
     "timestamp": 1648383483995,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "51717c30",
    "outputId": "1d7601da-9fb2-48b5-d866-74a760c17b0d"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9352/3427659439.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# import lightgbm as lgb                                 # gradient boosting 방식의 알고리즘입니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m                       \u001b[1;31m# 여러 개의 결정 트리를 임의적으로 학습하는 앙상블의 부스팅 유형 알고리즘입니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m              \u001b[1;31m# 사이킷런 패키지에서 제공하는 교차 검증을 위해 validation 세트를 나눠주는 함수입니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import lightgbm as lgb                                 # gradient boosting 방식의 알고리즘입니다.\n",
    "import l\n",
    "from xgboost import XGBRegressor                       # 여러 개의 결정 트리를 임의적으로 학습하는 앙상블의 부스팅 유형 알고리즘입니다.\n",
    "from sklearn.model_selection import KFold              # 사이킷런 패키지에서 제공하는 교차 검증을 위해 validation 세트를 나눠주는 함수입니다.\n",
    "from sklearn.preprocessing import LabelEncoder         # 문자 데이터를 정수형 데이터로 변환해주는 함수입니다.\n",
    "from sklearn.model_selection import GridSearchCV       # 최적의 파라미터를 찾기 위한 함수입니다.\n",
    "from sklearn.ensemble import GradientBoostingRegressor # 부스팅 유형 알고리즘입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2639df7",
   "metadata": {
    "id": "a2639df7"
   },
   "source": [
    "### `2.` 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a09f7d",
   "metadata": {
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1648383484984,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "e6a09f7d"
   },
   "outputs": [],
   "source": [
    "# train_data\n",
    "train_data = pd.read_csv('/content/gdrivd/MyDrive/Dacon/abalone age prediction contest/data/train.csv')\n",
    "\n",
    "# test_data\n",
    "test_data = pd.read_csv('/content/gdrivd/MyDrive/Dacon/abalone age prediction contest/data/test.csv')\n",
    "\n",
    "# submisiion_data\n",
    "submission_data = pd.read_csv('/content/gdrivd/MyDrive/Dacon/abalone age prediction contest/data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27ceb1",
   "metadata": {
    "id": "3d27ceb1"
   },
   "source": [
    "### `3.` 데이터 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34479d97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1648383485547,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "34479d97",
    "outputId": "8c011b63-f696-44e6-c403-0bf247e634f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(train_data.head())\n",
    "print(train_data.info())\n",
    "display(test_data.head())\n",
    "print(test_data.info())\n",
    "display(submission_data.head())\n",
    "print(submission_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0fe423",
   "metadata": {
    "id": "8b0fe423"
   },
   "source": [
    "### `4-1.` 데이터 분석 기법 EDA(탐색적 자료 분석) - ① 결측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af46e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648383485548,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "60af46e7",
    "outputId": "9612de86-8f0e-48ec-ad54-64dd88301dd7"
   },
   "outputs": [],
   "source": [
    "print('--------train_data 결측값--------\\n{}'.format(train_data.isna().sum()))\n",
    "print('--------test_data 결측값--------\\n{}'.format(test_data.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e48b4b",
   "metadata": {
    "id": "d3e48b4b"
   },
   "source": [
    "### `4-2.` 데이터 분석 기법 EDA(탐색적 자료 분석) - ② 특성별 상관관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723ec90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "executionInfo": {
     "elapsed": 2865,
     "status": "ok",
     "timestamp": 1648383488409,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "4723ec90",
    "outputId": "bc7b3978-5d53-4e76-f0bc-4eddf08df64e"
   },
   "outputs": [],
   "source": [
    "# 전체 특성별 상관관계를 확인하기 위해 문자형 데이터를 정수형 데이터로 \n",
    "le_encoder = LabelEncoder()\n",
    "\n",
    "# 'Gender'열의 데이터를 정수형 데이터로 인코딩합니다.\n",
    "train_data['Gender'] = le_encoder.fit_transform(train_data['Gender'])\n",
    "\n",
    "# 히트맵을 사용하여 특성별 상관관계를 확인합니다.\n",
    "plt.figure(figsize=(10,10))         # plt.figure(figsize=(12,12)): 12x12의 크기로 그림을 그려달라는 의미입니다.\n",
    "sns.heatmap(data=train_data.corr(), # data=: 시각화에 사용할 자료를 선택합니다.\n",
    "            annot=True,             # annot=: 셀 안에 숫자 표시 여부를 지정합니다.\n",
    "            fmt='.2f',              # fmt=: annot=True인 경우 숫자의 표시 형식을 지정합니다.\n",
    "            linewidths=.5,          # linewidths=: 각 셀을 나눌 선의 두께를 지정합니다. \n",
    "            cmap='Reds')            # cmap=: 표의 섹상을 지정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D8ArNoltF6zh",
   "metadata": {
    "id": "D8ArNoltF6zh"
   },
   "source": [
    "#### `4-2-1.` 필요 없는 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffad5ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1648383488968,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "3ffad5ee",
    "outputId": "84ceabc0-b308-49b6-d552-e08705fd1fb4"
   },
   "outputs": [],
   "source": [
    "# 위에서 상관관계를 확인하고 targer 데이터의 영향이 미미한 특성을 제거하겠습니다.\n",
    "train_data.drop(columns='id', inplace=True) # 'id' 컬럼을 제거하고 원본 데이터에 적용합니다.\n",
    "test_data.drop(columns='id', inplace=True)  # 'id' 컬럼을 제거하고 원본 데이터에 적용합니다.\n",
    "\n",
    "train_data.drop(columns='Gender', inplace=True) # 'id' 컬럼을 제거하고 원본 데이터에 적용합니다.\n",
    "test_data.drop(columns='Gender', inplace=True)  # 'id' 컬럼을 제거하고 원본 데이터에 적용합니다.\n",
    "\n",
    "# 제거한 뒤 데이터를 확인하겠습니다.\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iXtjPq6wGbwY",
   "metadata": {
    "id": "iXtjPq6wGbwY"
   },
   "source": [
    "### `4-3.` 데이터 분석 기법 EDA(탐색적 자료 분석) - ③ 통계량 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1MjamsfQ4WyL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648383488971,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "1MjamsfQ4WyL",
    "outputId": "9681e6f8-e051-4f0c-f25f-21a233229e81"
   },
   "outputs": [],
   "source": [
    "display(train_data.describe())\n",
    "display(test_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f95e0",
   "metadata": {
    "id": "f00f95e0"
   },
   "source": [
    "### `4-4.` 데이터 분석 기법 EDA(탐색적 자료 분석) - ④ 이상치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb654d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1648383489782,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "52eb654d",
    "outputId": "8389f797-f5e9-45d1-da75-aabc525334c9"
   },
   "outputs": [],
   "source": [
    "# 학습과 테스트 데이터의 이상치를 시각화하여 확인합니다.\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=train_data)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=test_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yZI1z0s2Dq3H",
   "metadata": {
    "id": "yZI1z0s2Dq3H"
   },
   "source": [
    "### `5.` 데이터 전처리 - ① 이상치\n",
    "1. 최소값과 최대값으로 변환\n",
    "2. 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cQXzMbPbkCg",
   "metadata": {
    "id": "5cQXzMbPbkCg"
   },
   "source": [
    "#### `5-1.` 이상치를 사분위수 최솟값과 최댓값으로 치환하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H1k1XYRoDu25",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648383489783,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "H1k1XYRoDu25"
   },
   "outputs": [],
   "source": [
    "# 각각의 이상치 처리 방법을 수행하기 위해 데이터를 복사하겠습니다.\n",
    "train_data1 = train_data.copy() # 사분위수 최솟값과 최댓값으로 변환\n",
    "train_data2 = train_data.copy() # 이상치 제거\n",
    "\n",
    "# 이상치를 사분위수 최솟값과 최댓값으로 변환하는 함수를 생성합니다.\n",
    "# 사분위수 최솟값 공식: Q1 - (1.5 * IQR)┃사분위수 최댓값 공식: Q3 + (1.5 * IQR)┃IQR 공식: Q3 - Q1\n",
    "def quartile_min_max(df, column) :\n",
    "\n",
    "  # np.percentile: 지정한 데이터의 원하는 사분위수를 반환합니다. (Q1: 25┃Q2: 50┃Q3: 75)\n",
    "  IQR = (np.percentile(df[column].values, 75) - np.percentile(df[column].values, 25))\n",
    "\n",
    "  # 사분위수 최솟값과 최댓값을 구합니다.\n",
    "  quartile_min = (np.percentile(df[column].values, 25) - (1.5 * IQR)) # 사분위수 최솟값 공식: Q1 - (1.5 * IQR)\n",
    "  quartile_max = (np.percentile(df[column].values, 75) + (1.5 * IQR)) # 사분위수 최댓값 공식: Q3 + (1.5 * IQR)\n",
    "\n",
    "  # 최솟값보다 작고 최댓값보다 큰 값의 행 인덱스를 추출합니다.\n",
    "  outlier_min_idx = df[column][df[column] < quartile_min].index # 최솟값보다 작은 값의 행 인덱스 번호를 outlier_min_idx 변수에 반환합니다.\n",
    "  outlier_max_idx = df[column][df[column] > quartile_max].index # 최댓값보다 큰 값의 행 인덱스 번호를 outlier_max_idx 변수에 반환합니다.\n",
    "\n",
    "  # outlier_idx 변수를 사용하여 해당하는 행의 값을 각각 최솟값과 최댓값으로 치환합니다.\n",
    "  df.loc[outlier_min_idx, column] = quartile_min # 지정한 컬럼의 위에서 구한 행 인덱스 번호의 값을 최솟값으로 치환합니다.\n",
    "  df.loc[outlier_max_idx, column] = quartile_max # 지정한 컬럼의 위에서 구한 행 인덱스 번호의 값을 최댓값으로 치환합니다.\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LDsTMGffb2T_",
   "metadata": {
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1648383490342,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "LDsTMGffb2T_"
   },
   "outputs": [],
   "source": [
    "# quartile_min_max 함수를 사용하여 이상치를 사분위수 최솟값과 최댓값으로 치환하겠습니다.\n",
    "# target 데이터와 상관관계가 높은 열을 우선적으로 수행하고 target 데이터는 치환하지 않겠습니다.\n",
    "columns = ['Shell Weight', 'Height', 'Diameter', 'Whole Weight', 'Lenght', 'Viscra Weight', 'Shucked Weight']\n",
    "\n",
    "# for column in columns :\n",
    "#   train_data1 = quartile_min_max(train_data1, column)\n",
    "\n",
    "for column in columns :\n",
    "  test_data = quartile_min_max(test_data, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-5MHD1txmp0G",
   "metadata": {
    "id": "-5MHD1txmp0G"
   },
   "source": [
    "#### `5-2.` 이상치를 제거하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5nQ3c2yJmuBp",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648383490343,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "5nQ3c2yJmuBp"
   },
   "outputs": [],
   "source": [
    "def outlier_del(df, column) :\n",
    "    \n",
    "    # IQR 값을 구합니다.\n",
    "    IQR = (np.percentile(df[column].values, 75) - np.percentile(df[column].values, 25))\n",
    "\n",
    "    # 사분위수 최솟값과 최댓값을 구합니다.\n",
    "    quartile_min = (np.percentile(df[column].values, 25) - (1.5 * IQR)) # 사분위수 최솟값 공식: Q1 - (1.5 * IQR)\n",
    "    quartile_max = (np.percentile(df[column].values, 75) + (1.5 * IQR)) # 사분위수 최댓값 공식: Q3 + (1.5 * IQR)\n",
    "\n",
    "    # 사분위수 최솟값과 최댓값을 벗어나는 모든 행의 인덱스 번호를 outlier_idx 변수에 반환합니다.\n",
    "    outlier_idx = df[column][(df[column] < quartile_min) | (df[column] > quartile_max)].index\n",
    "\n",
    "    # 위에서 구한 인덱스 번호를 사용하여 해당하는 행을 제거합니다.\n",
    "    df.drop(outlier_idx, axis=0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8egfOK6CgOhA",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648383490343,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "8egfOK6CgOhA"
   },
   "outputs": [],
   "source": [
    "# outlier_del 함수를 사용하여 이상치를 제거하겠습니다.\n",
    "# target 데이터와 상관관계가 높은 열을 우선적으로 수행하고 target 데이터는 제거하지 않겠습니다.\n",
    "columns = ['Shell Weight', 'Height', 'Diameter', 'Whole Weight', 'Lenght', 'Viscra Weight', 'Shucked Weight']\n",
    "\n",
    "for column in columns :\n",
    "  train_data2 = outlier_del(train_data2, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CSCgoF9aryLH",
   "metadata": {
    "id": "CSCgoF9aryLH"
   },
   "source": [
    "### `6.` 데이터 전처리 - ② 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6sGDXYJ1F9p2",
   "metadata": {
    "id": "6sGDXYJ1F9p2"
   },
   "source": [
    "#### `6-1.` 분리 전 데이터 '왜도' 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1jsdwj0NDYpB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648383490344,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "1jsdwj0NDYpB",
    "outputId": "4b4d4fe5-d1f5-415b-c9db-df961c02b1a3"
   },
   "outputs": [],
   "source": [
    "# 데이터 분리에 앞서 데이터들의 '왜도'를 확인합니다. '왜도' 값이 갖는 성질은 밑과 같습니다.\n",
    "# 왼쪽으로 치우침: 0 > skew┃오른쪽으로 치우침: 0 < skew┃정규분포를 따른다: 0 == skew\n",
    "# 즉 '왜도' 값이 0에 가까울 수록 정규분포를 따르는 좋은 데이터라고 할 수 있습니다.\n",
    "print('----------train_data1.skew----------\\n{}'.format(train_data1.skew()))\n",
    "print('----------train_data2.skew----------\\n{}'.format(train_data2.skew()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veCiq4LEGHzS",
   "metadata": {
    "id": "veCiq4LEGHzS"
   },
   "source": [
    "#### `6-2.` feature 데이터와 target 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WZaF3sXzB48s",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648383490345,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "WZaF3sXzB48s"
   },
   "outputs": [],
   "source": [
    "# 전체 데이터에서 feature 데이터와 target 데이터를 분리합니다.\n",
    "feature_train1 = train_data1.copy().drop(['Target'], axis=1) # target 데이터를 제외한 나머지 데이터를 복사합니다.\n",
    "feature_train2 = train_data2.copy().drop(['Target'], axis=1) # target 데이터를 제외한 나머지 데이터를 복사합니다.\n",
    "feature_test = test_data.copy() # 전체 데이터를 복사합니다.\n",
    "\n",
    "# 원본 데이터에서 target 데이터인 'Target' 열을 target 변수에 넘겨줍니다.\n",
    "# 데이터의 '왜도'를 확인했을 때 'Target'열이 유독 높게 나온 걸 확인할 수 있습니다. 이에 'Target' 데이터의 정규성을 높이고 분석에서 정확한 값을 얻기 위해 log 변환 취하도록 하겠습니다.\n",
    "# 데이터에 0이 있을 경우 log 변환 시 값이 무한대가 나오기 때문에 (x + 1)을 수행하여 0 → 1로 만들어주는 로그 변환 함수 np.log1p를 사용하겠습니다.\n",
    "target1 = np.log1p(train_data1['Target'].copy())\n",
    "target2 = np.log1p(train_data2['Target'].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96Ur1hGF5cTd",
   "metadata": {
    "id": "96Ur1hGF5cTd"
   },
   "source": [
    "### `7-1.` 모델 구축 및 함수를 사용한 학습 - ① light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wRfn7ZFKGOe9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1648309548165,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "wRfn7ZFKGOe9",
    "outputId": "c08c5a34-9c7e-49d3-a51e-8567787b0583"
   },
   "outputs": [],
   "source": [
    "# 예측하고자 하는 '나이'는 연속된 값으로 분류와 회귀 중 회귀에 해당합니다. 사용할 알고리즘은 트리 기반의 학습 알고리즘인 gradient boosting 방식의 LightGBM입니다.\n",
    "lgb_model = lgb.LGBMRegressor(num_leaves=10,          # 복잡성을 컨트롤하는 파라미터로, max_depth 보다 작게 설정해야 오버 피팅을 막을 수 있으며 다음과 같을 때 d = (2^max_depth) 보통 d의 60% 정도로 지정합니다.\n",
    "                              max_depth=4,            # 트리의 깊이를 제한하는 파라미터입니다.\n",
    "                              learning_rate=0.1,     # GBM 모듈은 초기 추정 값에서 시작하여 각각의 Tree 결과로 추정 값을 업데이트하는데 이때 변화의 크기를 지정하는 파라미터입니다.\n",
    "                              n_estimators=70,        # 결정 트리의 개수를 지정합니다.\n",
    "                              objective='regression', # 모델의 학습 목표를 지정합니다. 여기선 회귀 문제이므로 'regression'이고 분류 문제에선 'binary' 또는 'multiclass'를 사용합니다.\n",
    "                              min_child_samples=5,    # 최종 결정 클래스인 Leaf Node가 되기 위해서 최소한으로 필요한 데이터 개체의 수를 의미하며 과적합을 제어하는 파라미터입니다.\n",
    "                              subsample=0.8,          # 과적합을 제어하기 위해 데이터를 샘플링하는 비율을 정하는 파라미터입니다.\n",
    "                              random_state=23)        # 수행시마다 동일한 결과를 얻기 위해 seed 값을 주어 고정시키는 파라미터입니다.\n",
    "# oosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0, min_child_weight=0.001, min_child_samples=20, subsample=1, subsample_freq=0, colsample_bytree=1, reg_alpha=0, reg_lambda=0, random_state=None, n_jobs=- 1, silent=True, importance_type='split', **kwargs\n",
    "# 각각 다른 데이터를 한 번에 처리하기 위해 리스트 형태로 선언합니다.\n",
    "feature_data = [feature_train1, feature_train2]\n",
    "target_data = [target1, target2]\n",
    "\n",
    "# 이상치를 치환한 데이터와 제거한 데이터를 각각 학습하고 예측합니다.\n",
    "for feature_data, target_data in zip(feature_data, target_data) :\n",
    "\n",
    "  lgb_score = [] # 교차 검증을 수행할 때마다 NMAE score를 저장할 리스트 변수입니다.\n",
    "\n",
    "  lgb_kfold = KFold(n_splits=5,      # 교차 검증을 몇 번 할 것인지 즉 데이터를 몇 개로 나눌 것인지를 정하는 파라미터입니다.\n",
    "                    shuffle=True,    # 데이터를 섞을지 말지 여부를 정하는 파라미터입니다.\n",
    "                    random_state=23) # 수행시마다 동일한 결과를 얻기 위해 seed 값을 주어 고정시키는 파라미터입니다.\n",
    "\n",
    "  # KFold 객체에 split() 함수를 호출하면 폴드별 학습과 테스트 데이터의 행 인덱스를 배열로 반환합니다.\n",
    "  for train_idx, valid_idx in lgb_kfold.split(feature_data) :\n",
    "    x_train, x_valid = feature_data.iloc[train_idx], feature_data.iloc[valid_idx]\n",
    "    y_train, y_valid = target_data.iloc[train_idx], target_data.iloc[valid_idx]\n",
    "\n",
    "    # 학습을 진행합니다.\n",
    "    lgb_model.fit(x_train,                       # 학습할 feature data를 지정합니다.\n",
    "                  y_train,                       # 학습할 target data를 지정합니다.\n",
    "                  eval_set=[(x_valid, y_valid)], # validation data를 지정합니다.\n",
    "                  early_stopping_rounds=100,     # 성능의 향상이 이루어지지 않았을 경우 학습을 조기 종료하는 파라미터로 횟수를 지정하여 사용합니다.\n",
    "                  verbose=0)                     # 모델의 학습이 이루어지는 동안 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가를 정하는 파라미터입니다. (0: 출력 안함┃1: 자세히┃2: 함축적인 정보만)\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    y_pred = lgb_model.predict(x_valid)\n",
    "\n",
    "    # NMAE 평가산식 코드를 작성합니다.\n",
    "    mae = np.mean(np.abs(y_valid - y_pred))\n",
    "    score = mae / np.mean(np.abs(y_valid))\n",
    "\n",
    "    # NMAE score를 측정하여 리스트 변수에 붙여넣습니다.\n",
    "    lgb_score.append(score)\n",
    "    \n",
    "  # 교차 검증이 이루어질때마다 측정한 NMAE score의 평균을 출력합니다.\n",
    "  print('NMAE: ', np.mean(lgb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XOlz6P0A6nQG",
   "metadata": {
    "id": "XOlz6P0A6nQG"
   },
   "source": [
    "### `7-2.` 모델 구축 및 함수를 사용한 학습 - ② XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cFMdXppGOkP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1648309552477,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "3cFMdXppGOkP",
    "outputId": "c124f25a-31f2-4b16-f8ad-d76cca54d939"
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(max_depth=0,\n",
    "                         learning_rate=0.008,\n",
    "                         n_estimators=10,\n",
    "                         objective='reg:squarederror', # 모델의 학습 목표를 지정합니다. \n",
    "                         gamma=0,                      # 리프 노드의 추가 분할을 결정할 최소 손실 감소 값으로, 값이 높을수록 과적합 방지에 유리합니다.\n",
    "                         subsample=0.1,                # weak learner가 학습에 사용하는 데이터 샘플링 비율이다. 보통 0.5 ~ 1 사이로 사용합니다.\n",
    "                         random_state=23)\n",
    "\n",
    "# 이상치를 치환한 데이터와 제거한 데이터를 각각 학습하고 예측합니다.\n",
    "for feature_data, target_data in zip(feature_data, target_data) :\n",
    "\n",
    "  xgb_score = [] # 교차 검증을 수행할 때마다 NMAE score를 저장할 리스트 변수입니다.\n",
    "\n",
    "  xgb_kfold = KFold(n_splits=5,      # 교차 검증을 몇 번 할 것인지 즉 데이터를 몇 개로 나눌 것인지를 정하는 파라미터입니다.\n",
    "                    shuffle=True,    # 데이터를 섞을지 말지 여부를 정하는 파라미터입니다.\n",
    "                    random_state=23) # 수행시마다 동일한 결과를 얻기 위해 seed 값을 주어 고정시키는 파라미터입니다.\n",
    "\n",
    "  # KFold 객체에 split() 함수를 호출하면 폴드별 학습과 테스트 데이터의 행 인덱스를 배열로 반환합니다.\n",
    "  for train_idx, valid_idx in xgb_kfold.split(feature_train1) :\n",
    "    x_train, x_valid = feature_train1.iloc[train_idx], feature_train1.iloc[valid_idx]\n",
    "    y_train, y_valid = target1.iloc[train_idx], target1.iloc[valid_idx]\n",
    "\n",
    "    # 학습을 진행합니다.\n",
    "    xgb_model.fit(x_train,                       # 학습할 feature data를 지정합니다.\n",
    "                  y_train,                       # 학습할 target data를 지정합니다.\n",
    "                  eval_set=[(x_valid, y_valid)], # validation data를 지정합니다.\n",
    "                  early_stopping_rounds=100,     # 성능의 향상이 이루어지지 않았을 경우 학습을 조기 종료하는 파라미터로 횟수를 지정하여 사용합니다.\n",
    "                  verbose=False)                 # 모델의 학습이 이루어지는 동안 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가를 정하는 파라미터입니다. (0: 출력 안함┃1: 자세히┃2: 함축적인 정보만)\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    y_pred = xgb_model.predict(x_valid)\n",
    "\n",
    "    # NMAE 평가산식 코드를 작성합니다.\n",
    "    mae = np.mean(np.abs(y_valid - y_pred))\n",
    "    score = mae / np.mean(np.abs(y_valid))\n",
    "\n",
    "    # NMAE score를 측정하여 리스트 변수에 붙여넣습니다.\n",
    "    xgb_score.append(score)\n",
    "    \n",
    "  # 교차 검증이 이루어질때마다 측정한 NMAE score의 평균을 출력합니다.\n",
    "  print('NMAE: ', np.mean(xgb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2KT6dytR2u8g",
   "metadata": {
    "id": "2KT6dytR2u8g"
   },
   "source": [
    "### `7-3.` 모델 구축 및 함수를 사용한 학습 - ③ GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bjWjdBr3sUM",
   "metadata": {
    "id": "4bjWjdBr3sUM"
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(max_depth=4,\n",
    "                         learning_rate=0.09,\n",
    "                         n_estimators=90,\n",
    "                         objective='reg:squarederror', # 모델의 학습 목표를 지정합니다. \n",
    "                         gamma=0,                      # 리프 노드의 추가 분할을 결정할 최소 손실 감소 값으로, 값이 높을수록 과적합 방지에 유리합니다.\n",
    "                         subsample=0.8,                # weak learner가 학습에 사용하는 데이터 샘플링 비율이다. 보통 0.5 ~ 1 사이로 사용합니다.\n",
    "                         random_state=23)\n",
    "\n",
    "# 이상치를 치환한 데이터와 제거한 데이터를 각각 학습하고 예측합니다.\n",
    "for feature_data, target_data in zip(feature_data, target_data) :\n",
    "\n",
    "  xgb_score = [] # 교차 검증을 수행할 때마다 NMAE score를 저장할 리스트 변수입니다.\n",
    "\n",
    "  xgb_kfold = KFold(n_splits=5,      # 교차 검증을 몇 번 할 것인지 즉 데이터를 몇 개로 나눌 것인지를 정하는 파라미터입니다.\n",
    "                    shuffle=True,    # 데이터를 섞을지 말지 여부를 정하는 파라미터입니다.\n",
    "                    random_state=23) # 수행시마다 동일한 결과를 얻기 위해 seed 값을 주어 고정시키는 파라미터입니다.\n",
    "\n",
    "  # KFold 객체에 split() 함수를 호출하면 폴드별 학습과 테스트 데이터의 행 인덱스를 배열로 반환합니다.\n",
    "  for train_idx, valid_idx in xgb_kfold.split(feature_train1) :\n",
    "    x_train, x_valid = feature_train1.iloc[train_idx], feature_train1.iloc[valid_idx]\n",
    "    y_train, y_valid = target1.iloc[train_idx], target1.iloc[valid_idx]\n",
    "\n",
    "    # 학습을 진행합니다.\n",
    "    xgb_model.fit(x_train,                       # 학습할 feature data를 지정합니다.\n",
    "                  y_train,                       # 학습할 target data를 지정합니다.\n",
    "                  eval_set=[(x_valid, y_valid)], # validation data를 지정합니다.\n",
    "                  early_stopping_rounds=100,     # 성능의 향상이 이루어지지 않았을 경우 학습을 조기 종료하는 파라미터로 횟수를 지정하여 사용합니다.\n",
    "                  verbose=False)                 # 모델의 학습이 이루어지는 동안 발생하는 상세한 정보들을 표준 출력으로 자세히 내보낼 것인가를 정하는 파라미터입니다. (0: 출력 안함┃1: 자세히┃2: 함축적인 정보만)\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    y_pred = xgb_model.predict(x_valid)\n",
    "\n",
    "    # NMAE 평가산식 코드를 작성합니다.\n",
    "    mae = np.mean(np.abs(y_valid - y_pred))\n",
    "    score = mae / np.mean(np.abs(y_valid))\n",
    "\n",
    "    # NMAE score를 측정하여 리스트 변수에 붙여넣습니다.\n",
    "    xgb_score.append(score)\n",
    "    \n",
    "  # 교차 검증이 이루어질때마다 측정한 NMAE score의 평균을 출력합니다.\n",
    "  print('NMAE: ', np.mean(xgb_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ItqaDQxz8FGV",
   "metadata": {
    "id": "ItqaDQxz8FGV"
   },
   "source": [
    "### `8.` 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OTsQ6ao48JT2",
   "metadata": {
    "id": "OTsQ6ao48JT2"
   },
   "outputs": [],
   "source": [
    "def PreparationAnswerSheet(model, stored_file_name) :\n",
    "  # 테스트 데이터에 대한 예측을 진행하고 제출 형식에 맞게 파일을 csv 파일로 저장합니다.\n",
    "  submission_data['Target'] = np.expm1([0 if x < 0 else x for x in model.predict(feature_test)])\n",
    "  submission_data.to_csv('/content/gdrivd/MyDrive/Dacon/abalone age prediction contest/all model pred/'+str(stored_file_name), index=False)\n",
    "\n",
    "PreparationAnswerSheet(lgb_model, 'submission_lgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_EKPaefJ78hH",
   "metadata": {
    "id": "_EKPaefJ78hH"
   },
   "source": [
    "### model history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5OR_QZr_G7bO",
   "metadata": {
    "id": "5OR_QZr_G7bO"
   },
   "source": [
    "## 참고 사이트\n",
    "1. https://yssa.tistory.com/entry/Big-Data-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e_A9UUglUHtl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1646,
     "status": "ok",
     "timestamp": 1648383583795,
     "user": {
      "displayName": "박진완",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11571407450925957575"
     },
     "user_tz": -540
    },
    "id": "e_A9UUglUHtl",
    "outputId": "8a197e0f-f13e-4b8a-f262-84057ec7b723"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4WF3XuOrUVxv",
   "metadata": {
    "id": "4WF3XuOrUVxv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "abalone_age_prediction_contest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
