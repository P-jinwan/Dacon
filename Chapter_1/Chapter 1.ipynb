{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926942c7",
   "metadata": {},
   "source": [
    "# 1장 컴퓨터는 데이터에서 배운다\n",
    "- 머신 러닝의 일반적 개념 이해하기\n",
    "- 세 종류의 학습과 기본 용어 알아보기\n",
    "- 성공적인 머신 러닝 시스템을 설계하는 필수 요소 알아보기\n",
    "- 데이터 분석과 머신 러닝을 위한 파이썬을 설치하고 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04cbd9",
   "metadata": {},
   "source": [
    "## `1.1` 데이터를 지식으로 바꾸는 지능적인 시스템 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb8e89",
   "metadata": {},
   "source": [
    "현대 기술 시대에는 정형 또는 비정형 데이터가 매우 풍부합니다. 20세기 후반에 데이터에서 지식을 추출하여 예측하는 자기 학습 알고리즘과 관련된 **인공지능**의 하위 분야로 머신 러닝이 출현했습니다. 사람이 수동으로 대량의 데이터를 분석하여 규칙을 유도하고 모델을 만드는 대신, 머신 러닝이 데이터에서 더 효율적으로 지식을 추출하여 예측 모델과 데이터 기반의 의사 결정 성능을 점진적으로 향상시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a47b92",
   "metadata": {},
   "source": [
    "## `1.2` 머신 러닝의 세 가지 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e810c",
   "metadata": {},
   "source": [
    "<img src=\"./data_pictures/머신 러닝의 세 가지 학습 종류.jpg\" width=\"40%\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab8718",
   "metadata": {},
   "source": [
    "## `1.2.1` 지도 학습으로 미래 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12c677",
   "metadata": {},
   "source": [
    "지도 학습의 주요 목적은 레이블된 훈련 데이터에서 모델을 학습하여 본 적 없는 미래 데이터에 대해 예측을 만드는 것입니다. 여기서 **지도**는 희망하는 출력 신호(레이블)가 있는 일련의 샘플(입력 데이터)을 의미합니다.\n",
    "<img src=\"./data_pictures/지도 학습.PNG\" width=\"40%\" align=\"left\"></img>\n",
    "</br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br>\n",
    "### 분류: 클래스 레이블 예측\n",
    "분류는 지도 학습의 하위 카테고리입니다. 과거의 관측을 기반으로 새로운 샘플의 범주형 클래스 레이블을 예측하는 것이 목적입니다. 종류로는 **이진 분류**와 **다중 분류**가 있으며, yes or no 와 같이 두 개의 클래스 사이를 구분하려는 것이 이진 분류 입니다.\n",
    "<img src=\"./data_pictures/두 개의 클래스를 구분하는 결정 경계.PNG\" width=\"40%\" align=\"left\"></img>\n",
    "</br></br>\n",
    "그림은 30개의 훈련 샘플이 있는 이진 분류 작업의 개념을 나타냅니다. 15개의 샘플은 (-), 다른 15개의 샘플은 (+)로 레이블 되어 있습니다. 각 샘플이 두개의 x¹, x² 값에 연관되어 있으므로 2차원 데이터셋입니다. 지도 학습 알고리즘을 사용하여 두 클래스를 구분할 수 있는 규칙을 학습합니다. 이 규칙은 점선으로 나타난 **결정 경계**입니다.\n",
    "</br></br></br></br></br></br></br></br></br></br></br></br></br></br>\n",
    "### 회귀: 연속적인 출력 값 예측\n",
    "분류 작업은 범주형 순서가 없는 레이블을 샘플에 할당하는 것이라고 배웠씁니다. 두 번째 지도 학습의 종류는 연속적인 출력 값을 예측하는 **회귀** 분석입니다. 회귀는 **예측 변수(특성)**와 **반응 변수(타깃)**가 주어졌을 때 출력 값을 예측하기 위해 두 변수 사이의 관계를 찾습니다.\n",
    "</br>\n",
    "<img src=\"./data_pictures/선형 회귀의 예.PNG\" width=\"40%\" align=\"left\"></img>\n",
    "</br>\n",
    "그림은 선형 회귀의 개념을 나타냅니다. 특성 x와 타깃 y가 주어지면 데이터 포인트와 직선 사이 거리가 최소가 되는 직선을 그을 수 있습니다. 일반적으로 평균 제곱 거리를 사용합니다. 이렇게 데이터에서 학습한 직선의 기울기와 절편을 사용하여 새로운 데이터의 출력 값을 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb0ed",
   "metadata": {},
   "source": [
    "## `1.2.2` 비지도 학습으로 숨겨진 구조 발견"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c512f2",
   "metadata": {},
   "source": [
    "지도 학습에서는 모델을 훈련할 때 사전에 옳은 답을 알고 있습니다. 비지도 학습에서는 레이블되지 않거나 구조를 알 수 없는 데이터를 다룹니다. 비지도 학습 기법을 사용하면 알려진 출력 값이나 보상 함수의 도움을 받지 않고 의미 있는 정보를 추출하기 위해 데이터 구조를 탐색할 수 있습니다.\n",
    "### 군집: 서브그룹 찾기\n",
    "**군집**은 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브그룹 또는 **클러스터**로 조직하는 탐색적 데이터 분석 기법입니다. 분석 과정에서 만든 각 클러스터는 어느 정도 유사성을 공유하고 다른 클러스터와는 비슷하지 않은 샘플 그룹을 형성합니다.\n",
    "<img src=\"./data_pictures/군집.PNG\" width=\"40%\" align=\"left\"></img>\n",
    "</br></br>\n",
    "그림은 군집이 어떻게 레이블되지 않는 데이터를 특성 x¹과 x²의 유사도를 기반으로 세 개의 개별적인 그룹으로 조직화하는지 보여줍니다.\n",
    "</br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br></br>\n",
    "### 차원 축소: 데이터 압축\n",
    "비지도 학습의 또 다른 하위 분야는 **차원 축소**입니다. 고차원의 데이터를 다루어야 하는 경우는 흔합니다. 즉, 하나의 관측 샘플에 많은 측정 지표가 있습니다. 이로 인해 머신 러닝 알고리즘의 계산 성능과 저장 공간의 한계에 맞닥뜨릴 수 있습니다. 비지도 차원 축소는 잡음 데이터를 제거하기 위해 특성 전처리 단계에서 종종 적용하는 방법입니다. 잡음 데이터는 특정 알고리즘의 예측 성능을 감소시킬 수 있습니다.\n",
    "</br>\n",
    "<img src=\"./data_pictures/차원 축소의 예.PNG\" width=\"40%\" align=\"left\"></img>\n",
    "</br>그림은 비선형(nonlinear) 차원 축소를 적용하여 3D 스위스롤(Swiss Roll) 모양의 데이터를 새로운 2D 특성의 부분 공간으로 압축하는 예를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba0997",
   "metadata": {},
   "source": [
    "## `1.3` 기본 용어와 표기법 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd9275",
   "metadata": {},
   "source": [
    "머신 러닝은 방대한 분야이고 여러 학문이 관련되어 있기 때문에 여러 다른 용어로 같은 개념을 설명하는 경우를 머지않아 만나게 될 것입니다. 이어지는 두 번째 절에서는 머신 러닝 문헌에서 가장 널리 사용되는 용어를 소개합니다. 다양한 머신 러닝 자료를 읽을 때 참고로 사용하면 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce845fb0",
   "metadata": {},
   "source": [
    "## `1.3.1` 이 책에서 사용하는 표기법과 규칙"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba6ce36",
   "metadata": {},
   "source": [
    "<img src=\"./data_pictures/붓꽃 데이터셋.PNG\" width=\"60%\" align=\"left\"></img>\n",
    "그림은 머신 러닝 분야의 고전적인 예제인 붓꽃(iris) 데이터셋 일부를 보여 줍니다. 붓꽃 데이터셋은 Setosa, Versicolor, Virginica 세 종류 150개의 붓꽃 샘플을 담고 있습니다. 각 붓꽃 샘플은 데이터셋에서 하나의 행(row)으로 표현됩니다. 센티미터 단위의 측정값은 열(column)에 저장되어 있으며 데이터셋의 **특성(feature)**이라고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f19f3",
   "metadata": {},
   "source": [
    "## `1.3.2` 머신 러닝 용어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647d8c3",
   "metadata": {},
   "source": [
    "머신 러닝은 여러 연구 분야의 과학자들이 관여하기 때문에 분야가 방대하고 관련된 학문이 많습니다. 이 과정에서 많은 용어와 개념이 재발견되거나 재정의되었고 이미 알고 있는 내용이 다른 이름으로 등장하기도 합니다. 다음 목록에서 이 책과 다른 머신 러닝 책을 읽을 때 자주 등장하는 용어와 동의어를 정리했습니다.\n",
    "- **훈련 샘플** : 데이터셋을 나타내는 테이블의 행으로 동의어로는 관측, 레코드, 인스턴스, 예시가 있습니다.\n",
    "- **훈련** : 모델 피팅, 모수 모델의 경우 파라미터 추청과 비슷합니다.\n",
    "- **특성(x)** : 데이터 테이블이나 데이터 행렬의 열. 동의어로는 예측 변수, 변수, 입력, 속성, 공변량이 있습니다.\n",
    "- **타깃(y)** : 동의어로는 결과, 출력, 반응 변수, 종속 변수, 클래스 레이블, 정답이 있습니다.\n",
    "- **손실 함수** : 종종 비용 함수와 동의어로 사용합니다. 일부 자료에서는 손실 함수를 하나의 데이터 포인트에 대대 측정한 손실로 사용하고, 비용 함수는 전체 데이터셋에 대해 계산한 손실로 사용합니다. (손실 함수 값이 높으면 모델의 성능이 떨어짐을 의미합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59351717",
   "metadata": {},
   "source": [
    "## `1.4` 머신 러닝 시스템 구축 로드맵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d85cb",
   "metadata": {},
   "source": [
    "<img src=\"./data_pictures/머신 러닝의 작업 흐름.PNG\" width=\"70%\" align=\"left\"></img>\n",
    "그림은 예측 모델링에 머신 러닝을 사용하는 전형적인 작업 흐름을 보여 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c061a7",
   "metadata": {},
   "source": [
    "## `1.4.1` 전처리: 데이터 형태 갖추기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a3704",
   "metadata": {},
   "source": [
    "주어진 원본 데이터의 형태와 모습이 학습 알고리즘이 최적의 성능을 내기에 적합한 경우는 매우 드뭅니다. 데이터 전처리는 모든 머신 러닝 애플리케이션에서 가장 중요한 단계 중 하나입니다.  \n",
    "많은 머신 러닝 알고리즘에서 최적의 성능을 내려면 선택된 특성이 같은 스케일을 가져야 합니다.  \n",
    "머신 러닝 알고리즘이 훈련 데이터셋에서 잘 작동하고 새로운 데이터에서도 잘 일반화되는지 확인하려면 데이터셋을 랜덤하게 훈련 데이터셋과 테스트 데이터셋으로 나누어야 합니다. 훈련 데이터셋에서 머신 러닝 모델을 훈련하고 최적화합니다. 테스트 데이터셋은 별도로 보관하고 최종 모델을 평가하는 맨 마지막에 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef1174",
   "metadata": {},
   "source": [
    "## `1.4.2` 예측 모델 훈련과 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d766bf",
   "metadata": {},
   "source": [
    "여러 머신 러닝 알고리즘은 각기 다른 문제를 해결하기 위해 개발되었습니다. 분류 알고리즘은 저마다 태생적인 편향이 있습니다. 작업에서 아무런 가정도 하지 않는다면 어떤 하나의 분류 모델이 더 우월하다고 말할 수 없습니다. 여러 모델을 비교하기 전에 먼저 성능을 측정할 지표를 결정해야 합니다. 분류에서 널리 사용되는 지표는 **정확도(accuracy)**입니다. 정확도는 정확히 분류된 샘플 비율을 의미합니다. 또 머신 러닝 라이브러리들에서 제공하는 알고리즘의 기본 하이퍼파라미터가 현재 작업에 최적이라고 기대할 수 없습니다. 하이퍼파라미터란 데이터에서 학습하는 파라미터가 아니라 모델 성능을 향상하기 위해 사용하는 다이얼로 생각 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf221e",
   "metadata": {},
   "source": [
    "## `1.5` 머신 러닝을 위한 파이썬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe5cbe",
   "metadata": {},
   "source": [
    "파이썬은 데이터 과학 분야에서 가장 인기 있는 프로그래밍 언어입니다. 개발자와 오픈 소스 공동체가 매우 활발히 활동하고 있기 때문에 과학 컴퓨팅과 머신 러닝을 위한 유용한 라이브러리가 많이 개발되어 있습니다.  \n",
    "계산량이 많은 작업에서는 파이썬 같은 인터프리터 언어의 성능이 저수준 프로그래밍 언어보다 낮습니다. 포트란과 C언어로 만든 저수준 모듈 위에 구축된 넘파이와 사이파이 같은 라이브러리 덕택에 다차원 배열에서 벡터화된 연산을 빠르게 수행할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
