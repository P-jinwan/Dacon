{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce7760f7",
   "metadata": {},
   "source": [
    "\n",
    "## Fashion MNIST : 의류 클래스 예측\n",
    "이미지를 분석하여 의류 클래스를 분류 해보세요.\n",
    "### 1. train.csv / test.csv\n",
    "- index: index\n",
    "- label: 의류의 범주(0~9)\n",
    "- pixel(1~784): 이미지의 각 픽셀값(28×28=784)  \n",
    "\n",
    "### 2.  submission.csv (제출 파일 형식)  \n",
    "\n",
    "### 3. 라벨 종류\n",
    "- 0: T-shirt/top\n",
    "- 1: Trouser\n",
    "- 2: Pullover\n",
    "- 3: Dress\n",
    "- 4: Coat\n",
    "- 5: Sandal\n",
    "- 6: Shirt\n",
    "- 7: Sneaker\n",
    "- 8: Bag\n",
    "- 9: Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915848a",
   "metadata": {},
   "source": [
    "#### `1.` 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136bce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split     # 학습셋과 테스트셋을 나누기 위한 함수입니다.\n",
    "from tensorflow.keras.utils import to_categorical        # 타겟값의 원핫인코딩을 위한 함수입니다.\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # 모델이 최적의 성능을 낼 때 자동으로 저장해주는 함수입니다.\n",
    "from tensorflow.keras.callbacks import EarlyStopping     # 성능의 개선이 없는 경우 자동으로 학습을 종료하는 함수입니다.\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau # 성능의 개선이 없을 경우 학습률을 조절해 모델의 개선을 유도하는 함수입니다.\n",
    "from tensorflow.keras.layers import *                    # Conv2D, MaxPooling2D등 층을 만들때 필요한 함수가 있는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20acaea0",
   "metadata": {},
   "source": [
    "#### `2.` 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d08caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "submission_data = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1a0b2",
   "metadata": {},
   "source": [
    "#### `3-1.` 데이터 확인: 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4eed06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      0      2       0       0       0       0       0       0       0   \n",
       "1      1      9       0       0       0       0       0       0       0   \n",
       "2      2      6       0       0       0       0       0       0       0   \n",
       "3      3      0       0       0       0       1       2       0       0   \n",
       "4      4      3       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       5  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (60000, 786)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      3       0       0       0       0       0       0       0       0   \n",
       "4      4       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label\n",
       "0      0      0\n",
       "1      1      0\n",
       "2      2      0\n",
       "3      3      0\n",
       "4      4      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_data.shape (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "print('train_data.shape:', train_data.shape)\n",
    "display(test_data.head())\n",
    "print('test_data.shape', test_data.shape)\n",
    "display(submission_data.head())\n",
    "print('submission_data.shape', submission_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caf223",
   "metadata": {},
   "source": [
    "#### `3-2.` 데이터 확인: 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc2cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_data의 피처 데이터는 이미지의 각 픽셀을 데이터프레임화 시킨것으로 이미지로 시각화 하기 위해선 데이터를 픽셀화\n",
    "# 시킬 필요가 있습니다. 이미지의 각 픽셀 값은 28*28=784이기 때문에 데이터도 28샘플의 28특성으로 바꿔주어야 합니다.\n",
    "# 데이터의 차원을 변환하기 위해 넘파이 배열로 받겠습니다. 또한 피쳐의 0번째와 1번째는 인덱스값으로 2번째 컬럼 데이터\n",
    "# 부터 가져옵니다.\n",
    "plt.imshow(np.array(train_data.iloc[23, 2:]) # 23행에 2번째부터 끝까지의 컬럼 데이터를 반환합니다.\n",
    "           .reshape(28, 28),                 # 데이터의 형태를 x28*y28로 변환합니다.\n",
    "           cmap='gray')                      # 이미지 출력 색상을 회색으로 지정합니다.\n",
    "plt.show()                                   # 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed687e5",
   "metadata": {},
   "source": [
    "#### `4.` 데이터 크기 변환: train_data와 test_data의 크기 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee37d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature_data.shape (60000, 28, 28, 1)\n",
      "test_feature_data.shape (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 크기 변환을 위해 특성의 개수를 784개로 조정하면서 동시에 feature와 target 데이터를 분리하겠습니다.\n",
    "train_feature_data = train_data.copy().drop(['index', 'label'], axis=1)\n",
    "test_feature_data = test_data.copy().drop(['index'], axis=1)\n",
    "train_target_data = train_data['label'].copy()\n",
    "\n",
    "# 분리된 데이터의 크기를 각 이미지의 픽셀에 맞게 28 * 28로 변환합니다.\n",
    "# 여기서 reshape(-1, 28, 28, 1)은 (batch_size, width, height, channel)을 의미합니다.\n",
    "# batch_size를 -1로 두면 컬럼의 개수의 따라 행의 개수를 자동으로 조절해줍니다.\n",
    "# channel을 1로 두는 이유는 fashion MNIST 이미지는 Gray Scale로 1개의 채널만 필요로 하기 때문입니다.\n",
    "train_feature_data = train_feature_data.values.reshape(-1, 28, 28, 1)\n",
    "test_feature_data = test_feature_data.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 변환된 데이터의 크기를 확인합니다.\n",
    "print('train_feature_data.shape', train_feature_data.shape)\n",
    "print('test_feature_data.shape', test_feature_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1206f97",
   "metadata": {},
   "source": [
    "#### `5.` 데이터 분할: training set와  validation set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e2ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (42000, 28, 28, 1)\n",
      "y_train.shape: (42000,)\n",
      "x_valid.shape: (18000, 28, 28, 1)\n",
      "y_valid.shape: (18000,)\n"
     ]
    }
   ],
   "source": [
    "# training set(x_train, y_train)와 validation set(x_test, y_test)를 나눕니다.\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_feature_data,         # 나누고자 하는 feature데이터를 지정합니다.\n",
    "                                                    train_target_data,          # 나누고자 하는 target데이터를 지정합니다.\n",
    "                                                    test_size=0.3,              # 전체 데이터의 30%를 validation set로 구성합니다.\n",
    "                                                    random_state=23,            # seed 값을 지정합니다.\n",
    "                                                    shuffle=True,               # 데이터를 섞을지 말지 여부를 지정합니다.\n",
    "                                                    stratify=train_target_data) # target데이터가 한쪽에 편향되지 않게 일정한 비율로 나누어줍니다.\n",
    "\n",
    "\n",
    "# 나누어진 데이터의 크기를 확인합니다.\n",
    "print('x_train.shape:', x_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('x_valid.shape:', x_valid.shape)\n",
    "print('y_valid.shape:', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265dc5f",
   "metadata": {},
   "source": [
    "#### `6.` 데이터 전처리: 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cf17fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 최소값: 0.0, 최대값: 1.0\n",
      "x_valid의 최소값: 0.0, 최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 이미지의 각 픽셀값(0 ~ 255)을 0 ~ 1 값으로 정규화 시켜 연산비용을 줄이고 최적의 성능을 유도합니다.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_valid = x_valid.astype('float32') / 255\n",
    "\n",
    "# 정규화된 데이터의 최소값과 최대값을 확인합니다.\n",
    "print('x_train의 최소값: {}, 최대값: {}'.format(np.min(x_train), np.max(x_train)))\n",
    "print('x_valid의 최소값: {}, 최대값: {}'.format(np.min(x_valid), np.max(x_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24b8c6",
   "metadata": {},
   "source": [
    "#### `7.` 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5042637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential 모델을 cnn_model 변수에 할당합니다.\n",
    "cnn_model = keras.Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=2, padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "    \n",
    "cnn_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "    \n",
    "cnn_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "    \n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(1024, activation ='relu'))\n",
    "cnn_model.add(Dense(512, activation ='relu'))\n",
    "cnn_model.add(Dense(256, activation ='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(10, activation ='softmax'))\n",
    "          \n",
    "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34c5d0",
   "metadata": {},
   "source": [
    "#### `8.` 모델 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1dc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 성능이 개선되지 않을 때 자동으로 학습을 종료시켜주는 함수입니다.\n",
    "es = EarlyStopping(\n",
    "    monitor='val_accuracy', # 모니터링할 지표를 지정합니다.\n",
    "    patience=50)            # 성능이 개선되지 않을 때 허용 횟수를 지정합니다. (51번째에도 개선이 없으면 종료)\n",
    "\n",
    "# 모델이 최적의 성능을 낼 때 자동으로 저장을 해주는 함수입니다.\n",
    "mc = ModelCheckpoint(\n",
    "    filepath='./cnn_model_checkpoints/', # 파일을 저장할 경로입니다.\n",
    "    monitor='val_accuracy',              # 모니터링할 지표를 지정합니다.\n",
    "    verbose=0,                           # 저장 메세지 출력 여부를 지정합니다. (0: 출력x, 1: 출력 o)\n",
    "    save_weights_only=True,              # 가중치를 저장할지 여부를 지정합니다.\n",
    "    save_best_only=True)                 # 이전보다 성능이 좋을 경우에만 저장하도록 합니다.\n",
    "\n",
    "# 모델의 성능이 향상되지 않는 경우 학습률을 낮추는 함수입니다.\n",
    "rlrop = ReduceLROnPlateau(\n",
    "    factor=0.5, # 기준을 만족할때마다 학습률을 얼만큼 감소시킬지 정합니다.\n",
    "    patience=5, # 개선되지 않는 에포크를 몇 번 허용할지 정합니다. (6번째에도 개선이 없으면 학습률 조정)\n",
    "    verbose=0)  # 학습률 조정시 메세지 출력 여부를 지정합니다. (0: 출력x, 1: 출력 o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6bfcbd",
   "metadata": {},
   "source": [
    "#### `9.` 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983328d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 281s 3s/step - loss: 0.9985 - accuracy: 0.6245 - val_loss: 3.3537 - val_accuracy: 0.1000\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 280s 3s/step - loss: 0.5961 - accuracy: 0.7792 - val_loss: 4.6239 - val_accuracy: 0.1122\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 276s 3s/step - loss: 0.4978 - accuracy: 0.8191 - val_loss: 4.2507 - val_accuracy: 0.1543\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.4454 - accuracy: 0.8403 - val_loss: 2.7331 - val_accuracy: 0.2279\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.4079 - accuracy: 0.8528 - val_loss: 1.2568 - val_accuracy: 0.5939\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3846 - accuracy: 0.8633 - val_loss: 0.6494 - val_accuracy: 0.7567\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3654 - accuracy: 0.8704 - val_loss: 0.3605 - val_accuracy: 0.8690\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3470 - accuracy: 0.8756 - val_loss: 0.3095 - val_accuracy: 0.8894\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3322 - accuracy: 0.8813 - val_loss: 0.2863 - val_accuracy: 0.8943\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3268 - accuracy: 0.8838 - val_loss: 0.2724 - val_accuracy: 0.9010\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.3174 - accuracy: 0.8865 - val_loss: 0.2770 - val_accuracy: 0.8997\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 278s 3s/step - loss: 0.3058 - accuracy: 0.8921 - val_loss: 0.3099 - val_accuracy: 0.8893\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 281s 3s/step - loss: 0.2980 - accuracy: 0.8926 - val_loss: 0.2620 - val_accuracy: 0.9032\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 283s 3s/step - loss: 0.2971 - accuracy: 0.8938 - val_loss: 0.2734 - val_accuracy: 0.9014\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 278s 3s/step - loss: 0.2892 - accuracy: 0.8952 - val_loss: 0.2715 - val_accuracy: 0.9005\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.2873 - accuracy: 0.8970 - val_loss: 0.2279 - val_accuracy: 0.9174\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 276s 3s/step - loss: 0.2767 - accuracy: 0.8993 - val_loss: 0.2379 - val_accuracy: 0.9133\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 277s 3s/step - loss: 0.2703 - accuracy: 0.9027 - val_loss: 0.2484 - val_accuracy: 0.9102\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 276s 3s/step - loss: 0.2683 - accuracy: 0.9041 - val_loss: 0.2411 - val_accuracy: 0.9124\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 302s 3s/step - loss: 0.2656 - accuracy: 0.9050 - val_loss: 0.2529 - val_accuracy: 0.9086\n",
      "Epoch 21/1000\n",
      "  3/100 [..............................] - ETA: 3:54 - loss: 0.2642 - accuracy: 0.9000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1664984702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_history = cnn_model.fit(x_train,                            # 학습할 피쳐 데이터를 지정합니다.\n\u001b[0m\u001b[0;32m      2\u001b[0m                               \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m                            \u001b[1;31m# 학습할 타겟 데이터를 지정합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m                        \u001b[1;31m# 에포크 횟수를 지정합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m420\u001b[0m\u001b[1;33m,\u001b[0m                     \u001b[1;31m# 420개씩 학습을 진행합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 검증 데이터를 지정합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep_learning_practice\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history = cnn_model.fit(x_train,                            # 학습할 피쳐 데이터를 지정합니다.\n",
    "                              y_train,                            # 학습할 타겟 데이터를 지정합니다.\n",
    "                              epochs=1000,                        # 에포크 횟수를 지정합니다.\n",
    "                              batch_size=420,                     # 420개씩 학습을 진행합니다.\n",
    "                              validation_data=(x_valid, y_valid), # 검증 데이터를 지정합니다.\n",
    "                              callbacks=[es, mc, rlrop])          # 콜백함수를 지정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7986f9",
   "metadata": {},
   "source": [
    "#### `10.` 모델의 학습 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# 에포크별 정확도\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# 에포크별 손실률\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e05b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
